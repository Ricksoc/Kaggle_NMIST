{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n\nThe training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n\nEach pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n\nFor example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import training and test files and examine basic information\ntest = pd.read_csv(\"../input/test.csv\")\ntrain = pd.read_csv(\"../input/train.csv\")\ndisplay(train.head(1))\ndisplay(train.isna().sum().any())\ndisplay(test.shape)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Examine example digit by extracting a single image row, converting to an array and then reshaping to 28x28\n#There are no NaNs in the training data set\nX_disp = np.array(train.iloc[4,1:])\nX_disp = X_disp.reshape(28,28)\n\nplt.figure()\nplt.axis('off')\nplt.imshow(X_disp)\nplt.title('Digit is {}'.format(train.iloc[4,1]));\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display row of an example of each digit which run 0-9\nax1 = plt.figure(figsize=(20,4))\nfor i in range(10):\n    idx = (train['label']==i).idxmax()\n    x = np.array(train.iloc[idx,1:]).reshape(28,28)\n    lab = train.iloc[idx,0]\n    plt.subplot(1,10,i+1)\n    plt.axis('off')\n    plt.imshow(x)\n    plt.title('Digit is {}'.format(lab))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labs = test.iloc[:,0]\ntest_labs.shape\nbase_pred = np.random.randint(0,9,size = (28000,))\naccuracy_score(test_labs,base_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separate training data into train and validation\nX = train.iloc[:,1:]\ny = train.iloc[:,0]\n\nX_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size=0.25,random_state = 27)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"Simple random forest on all training data has 93.8% accuracy on training data set. Next I will simplify the model. From the images of the digits most pixels are null values, thus the number of features can likely be reduced by removing these without compromising the model. This should at the very least improve the speed of the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.iloc[1,:].hist(bins=10) #Inspect a histogram of image intensities to see what proportion of piexls have high intesnity.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, there is a large proportion of null values so it is likely that pca can reduce the number of components without compromising accuracy. Next step is to determine the optimum number of components."},{"metadata":{"trusted":true},"cell_type":"code","source":"n_components = ([1,2,3,4,5,10,20,50,100,200,500,X_train.shape[1]])\nvar_ratio = np.zeros(len(n_components))\ni=0;\nfor components in n_components:\n    pca = PCA(n_components = components)\n    pca.fit(X_train)\n    var_ratio[i] = sum(pca.explained_variance_ratio_)\n    i+=1   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.plot(n_components,var_ratio,'k.-')\nplt.xscale(\"log\")\nplt.yticks(np.linspace(0.2,1.0,9))\nplt.xticks(np.arange(1,1000,100))\nplt.xlabel(\"number of PCA components\",size=20)\nplt.ylabel(\"variance ratio\",size=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"~200 component capture 95% of the variance. I experimented with scaling the data but this increased the number of components required for 95% variance and reduced model accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"#now use pca to transform the data with 200 components\npca = PCA(n_components=200)\nX_train_pca = pca.fit_transform(X_train)\nX_valid_pca = pca.transform(X_valid)\ntest_pca = pca.transform(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will try random forest and k-nearest neighbours to preidct the digits. I will use the validation data set to optimise the hyperparameters. I have also tried Random Forest but kNN performs better so I will continue with that."},{"metadata":{"trusted":true},"cell_type":"code","source":"#KNN unoptimised\nknn = KNeighborsClassifier()\nknn.fit(X_train_pca,y_train)\nknn_predict = knn.predict(X_valid_pca[:2000])\naccuracy = accuracy_score(y_valid[:2000],knn_predict)\ndisplay('The unoptimised knn model predicts the validation data set with an accuracy of {0:.3f}'.format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Having experimented with tuned and untuned models I have so far achieved better performance with more training data but an untuned model - I have been using less data with the tuned model due to speed. This could be because for this data set more traininf data is required, or because by tuning with a trainig set of only 500 images I am using to small a set to optimally tune the model. For this final run I will tune the model with 1000 data points and the give the tuned model the full training data set. I will submit whichever of the tuned and untuned model has the highest accuracy on 2000 images from the validation data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"#KNN tuning\n\n#Hyper Parameters\nparams = {'n_neighbors':[5,7,9,11,13,15],\n          'leaf_size':[5,10,15,20,25,30], #small leaf size reduce the model speed too much\n          'weights':['uniform', 'distance'],\n          'algorithm':['auto', 'ball_tree','kd_tree','brute'],\n          }\n\nknn_tuned = GridSearchCV(knn, param_grid=params)\nknn_tuned.fit(X_train_pca[:1000],y_train[:1000]) #only using 500 data points to increase speed\n\nknn_params = knn_tuned.best_params_\nprint(\"Optimum Hyper Parameters:\\n\",knn_params)\n\nprediction=knn_tuned.predict(X_valid_pca[:2000])\naccuracy = accuracy_score(prediction,y_valid[:2000])\n\nprint(\"Accuracy:{:.3f}\".format(accuracy))\nprint(\"Confusion Matrix:\\n\",confusion_matrix(prediction,y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Construct KNN model using optimum hyperparamters and more training data.\nknn_tuned.fit(X_train_pca,y_train)\nknn_tuned_predict = knn_tuned.predict(X_valid_pca[:2000])\naccuracy = accuracy_score(y_valid[:2000],knn_tuned_predict)\ndisplay('The optimised knn model predicts the validation data set with an accuracy of {0:.3f}'.format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create submission files\n\n#kNN\nknn_predict = knn.predict(test_pca)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(test_pca)+1)),\n                         \"Label\": rf_predict})\nsubmissions.to_csv(\"kNN_NMIST.csv\", index=False, header=True)\n\n#KNN Tuned\nknn_tuned_predict = knn_tuned.predict(test_pca)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(test_pca)+1)),\n                         \"Label\": knn_predict})\nsubmissions.to_csv(\"kNN_Tuned_NMIST.csv\", index=False, header=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}